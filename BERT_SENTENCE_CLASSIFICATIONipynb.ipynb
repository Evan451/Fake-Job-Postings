{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUWzK4knI_FT",
    "outputId": "61427f98-c89d-4cd4-e258-ecf2e995e5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 281.3 MB 38 kB/s \n",
      "\u001b[K     |████████████████████████████████| 142 kB 15.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 198 kB 64.0 MB/s \n",
      "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "! pip install -q pyspark==3.2.0 spark-nlp==3.4.2. #requirements για να το τρέξουμε στο google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "aSdXDeNKJGRk",
    "outputId": "4f4fc7c9-081b-473e-d9cd-bc09e0e9d520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 3.4.2\n",
      "Apache Spark version: 3.2.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://dcf59582f6cd:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa9c2c7a050>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ξεκινάμε τη sparknlp\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start(gpu = True, spark32=True) \n",
    "# for GPU training >> sparknlp.start(gpu = True) colab άρα είναι εφικτό\n",
    " # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
    "\n",
    "from sparknlp.base import *                  # απαραίτητα κυρίως για bert και embeddings, classifierdl\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version) #ένα τσεκ για τις εκδόσεις που εγκαταστήσαμε στο session μας \n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rzifh49XJaPI",
    "outputId": "84edccdb-2fd6-4e94-9f4c-781d153f7846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- description: string (nullable = true)\n",
      " |-- fraudulent: string (nullable = true)\n",
      "\n",
      "+--------------------+----------+\n",
      "|         description|fraudulent|\n",
      "+--------------------+----------+\n",
      "|Food52, a fast-gr...|         0|\n",
      "|Organised - Focus...|         0|\n",
      "|Our client, locat...|         0|\n",
      "|THE COMPANY: ESRI...|         0|\n",
      "|JOB TITLE: Itemiz...|         0|\n",
      "|Job OverviewApex ...|         0|\n",
      "|Your Responsibili...|         0|\n",
      "|Who is Airenvy?He...|         0|\n",
      "|Implementation/Co...|         0|\n",
      "|The Customer Serv...|         0|\n",
      "|Position : #URL_8...|         0|\n",
      "|TransferWise is t...|         0|\n",
      "|The Applications ...|         0|\n",
      "|Event Industry In...|         0|\n",
      "|Are you intereste...|         0|\n",
      "|About Vault Drago...|         0|\n",
      "|We are looking fo...|         0|\n",
      "|Government fundin...|         0|\n",
      "|Kettle is hiring ...|         0|\n",
      "|Experienced Proce...|         0|\n",
      "|IntelliBright is ...|         0|\n",
      "|Want to be part o...|         0|\n",
      "|The position repo...|         0|\n",
      "|#URL_eda2500ddced...|         0|\n",
      "|We are a canary w...|         0|\n",
      "|Hello,Wish you ar...|         0|\n",
      "|We are currently ...|         0|\n",
      "|HAAD/DHA Licensed...|         0|\n",
      "|(We have more tha...|         0|\n",
      "|The Customer Serv...|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *  # δε χρειαζόμαστε όλες τις sql συναρτήσεις της pyspark , αλλά εφόσον δεν επιβαρύνουν τα resources το αφήνουμε\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.training import *\n",
    "df = spark.read.option(\"header\",\"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .option(\"multiLine\", \"true\") \\\n",
    "  .option(\"quote\",\"\\\"\") \\\n",
    "  .option(\"escape\",\"\\\"\")\\\n",
    "  .option(\"ignoreTrailingWhiteSpace\", True) \\\n",
    "  .csv(\"job_postings.csv\")\n",
    "\n",
    "df = df.drop(*[c for c in df.columns if c not in {\"description\",\"fraudulent\"}])  # το βήμα αυτό έχει εξηγηθεί και στο preprocess σε άλλο αρχείο\n",
    "df.printSchema()                                                                  # θέλουμε μόνο description και fraudulent ως στήλες \n",
    "\n",
    "df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nab9KuyFKJjf",
    "outputId": "b998341d-7a0f-4fa5-fe81-5eaae0b93c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_small_bert_L8_128 download started this may take some time.\n",
      "Approximate size to download 20.5 MB\n",
      "[OK!]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3429\n",
      "           1       0.00      0.00      0.00       185\n",
      "\n",
      "    accuracy                           0.95      3614\n",
      "   macro avg       0.47      0.50      0.49      3614\n",
      "weighted avg       0.90      0.95      0.92      3614\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# πάμε να φτιάξουμε το pipeline για να χρησιμοποιήσουμε έναν bert sentence embedder, για λόγους χρόνου βάζουμε έναν small bert\n",
    "# eεπειδή εδώ δε φαίνεται η ανάθεση διανυσμάτων στις λέξεις του description (προτάσεις εδώ με τον sentence embedder)\n",
    "# έχουμε κάνει και έναν άλλον bert embedder με mbedder finisher για να φαίνονται και τα διανύσματα κάθε λέξης εκεί \n",
    "\n",
    "\n",
    "# μοντέλο το sent_small_bert_L8_128\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"description\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "embeddingsSentence = BertSentenceEmbeddings().pretrained(\"sent_small_bert_L8_128\", \"en\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"fraudulent\")\\\n",
    "    .setMaxEpochs(7)\\\n",
    "    .setEnableOutputLogs(True)\n",
    "\n",
    "bert_clf_pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    embeddingsSentence,\n",
    "    classsifierdl\n",
    "])\n",
    "\n",
    "splits = df.randomSplit([0.8, 0.2])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "b_clf_pipelineModel = bert_clf_pipeline.fit(train)\n",
    "preds = b_clf_pipelineModel.transform(test)\n",
    "preds_df = preds.select('fraudulent','description',\"class.result\").toPandas()\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(preds_df['fraudulent'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwkeMUsuS8Kf",
    "outputId": "de6ed70f-9aca-4289-9137-464514ecd24f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 19\n",
      "+----------+-----+\n",
      "|fraudulent|count|\n",
      "+----------+-----+\n",
      "|         0|17014|\n",
      "|         1|16454|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from sparknlp.base import *                           # ιδιες εισαγωγες απλα χρησιμοποιηθηκαν αρκετες φορες και για να μην ξανατρεχει απο την αρχη ο \n",
    "from sparknlp.annotator import *                      # bert και ξανα με το majordf \n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# we will try oversampling on our dataset ( it is very imbalanced though since 95% are zeros on fraudulent col)\n",
    "\n",
    "major_df = df.filter(col(\"fraudulent\") == 0)\n",
    "minor_df = df.filter(col(\"fraudulent\") == 1)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))\n",
    "# duplicate the minority rows (ones)\n",
    "a = range(ratio)\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n",
    "\n",
    "df = major_df.unionAll(oversampled_df)\n",
    "# Maybe this gives us a more balanced dataset\n",
    "df.groupBy('fraudulent').count().show()   # για να δούμε τώρα αν έφτιαξε το dataset , έφτιαξε αρκετά \n",
    "# δημιουργήσαμε νέους άσους(εγγραφές με fraudulent 1 ), ωστόσο τα αποτελέσματα θα είναι λίγο πλασματικά \n",
    "# μιας και απλά αυξήσαμε σχεδόν για να φτάσουν στα ίδια μεγέθη"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8W_OBjR5HCf",
    "outputId": "e354125c-e6a3-484d-ded0-a8d7301afd67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_small_bert_L8_128 download started this may take some time.\n",
      "Approximate size to download 20.5 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3408\n",
      "           1       0.49      1.00      0.66      3287\n",
      "\n",
      "    accuracy                           0.49      6695\n",
      "   macro avg       0.25      0.50      0.33      6695\n",
      "weighted avg       0.24      0.49      0.32      6695\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#OVERSAMPLED DATASET - BERT SENTENCE CLASSIFIERDL\n",
    "\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"description\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "embeddingsSentence = BertSentenceEmbeddings().pretrained(\"sent_small_bert_L8_128\", \"en\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"fraudulent\")\\\n",
    "    .setMaxEpochs(7)\\\n",
    "    .setEnableOutputLogs(True)\n",
    "\n",
    "bert_clf_pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    embeddingsSentence,\n",
    "    classsifierdl\n",
    "])\n",
    "\n",
    "splits = df.randomSplit([0.8, 0.2])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "b_clf_pipelineModel = bert_clf_pipeline.fit(train)\n",
    "preds = b_clf_pipelineModel.transform(test)\n",
    "preds_df = preds.select('fraudulent','description',\"class.result\").toPandas()\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(preds_df['fraudulent'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fEMW_iI94nT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_SENTENCE_CLASSIFICATIONipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

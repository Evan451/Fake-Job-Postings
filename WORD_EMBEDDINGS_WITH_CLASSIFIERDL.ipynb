{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jfCj4LRqnS0",
    "outputId": "b48d0f0a-34bd-4993-9a90-ac7117646e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 281.3 MB 38 kB/s \n",
      "\u001b[K     |████████████████████████████████| 142 kB 14.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 198 kB 46.8 MB/s \n",
      "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "! pip install -q pyspark==3.2.0 spark-nlp==3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "u7jSVOTB1SYp",
    "outputId": "a558432c-c749-4eb9-b327-5a5489a11bc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 3.4.2\n",
      "Apache Spark version: 3.2.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a858e18ec006:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff6b061d4d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start(gpu = True, spark32=True) \n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())          # check για versions sparknlp και pyspark\n",
    "print(\"Apache Spark version:\", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_F2A2wR81YTa",
    "outputId": "dfcbd394-ec42-4854-8157-11015b656499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|         description|fraudulent|\n",
      "+--------------------+----------+\n",
      "|Food52, a fast-gr...|         0|\n",
      "|Organised - Focus...|         0|\n",
      "|Our client, locat...|         0|\n",
      "|THE COMPANY: ESRI...|         0|\n",
      "|JOB TITLE: Itemiz...|         0|\n",
      "|Job OverviewApex ...|         0|\n",
      "|Your Responsibili...|         0|\n",
      "|Who is Airenvy?He...|         0|\n",
      "|Implementation/Co...|         0|\n",
      "|The Customer Serv...|         0|\n",
      "|Position : #URL_8...|         0|\n",
      "|TransferWise is t...|         0|\n",
      "|The Applications ...|         0|\n",
      "|Event Industry In...|         0|\n",
      "|Are you intereste...|         0|\n",
      "|About Vault Drago...|         0|\n",
      "|We are looking fo...|         0|\n",
      "|Government fundin...|         0|\n",
      "|Kettle is hiring ...|         0|\n",
      "|Experienced Proce...|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- description: string (nullable = true)\n",
      " |-- fraudulent: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"quote\", \"\\\"\")\\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreTrailingWhiteSpace\", True) \\\n",
    "    .csv(\"job_postings.csv\")\n",
    "\n",
    "df = df.select(\"description\", \"fraudulent\") # κρατάμε με select εδώ τις δύο στήλες που χρειαζόμαστε\n",
    "df.show()\n",
    "df.printSchema() # βλέπουμε το dataset και ελέγχουμε αν φορτώθηκε σωστά το dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3SB-PMC1ZOc",
    "outputId": "1b6d5c7a-b06a-4db7-e61b-2c61a201c2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 19\n",
      "+----------+-----+\n",
      "|fraudulent|count|\n",
      "+----------+-----+\n",
      "|         0|17014|\n",
      "|         1|16454|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# we will try oversampling on our dataset ( it is very imbalanced though since 95% are zeros on fraudulent col)\n",
    "\n",
    "major_df = df.filter(col(\"fraudulent\") == 0)\n",
    "minor_df = df.filter(col(\"fraudulent\") == 1)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))\n",
    "# duplicate the minority rows (ones)\n",
    "a = range(ratio)\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n",
    "# combine both oversampled minority rows and previous majority rows\n",
    "df = major_df.unionAll(oversampled_df)\n",
    "# Maybe this gives us a more balanced dataset\n",
    "df.groupBy('fraudulent').count().show()   # για να δούμε τώρα αν έφτιαξε το dataset , έφτιαξε αρκετά \n",
    "# δημιουργήσαμε νέους άσους(εγγραφές με fraudulent 1 ), ωστόσο τα αποτελέσματα θα είναι λίγο πλασματικά \n",
    "# μιας και απλά αυξήσαμε σχεδόν για να φτάσουν στα ίδια μεγέθη"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQ-yMxFN3_HB",
    "outputId": "391a28e7-e027-4488-80c3-6fc019f8a2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      3385\n",
      "           1       0.95      0.90      0.92      3248\n",
      "\n",
      "    accuracy                           0.93      6633\n",
      "   macro avg       0.93      0.93      0.93      6633\n",
      "weighted avg       0.93      0.93      0.93      6633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Oversampled dataset Word Embeddings Classifierdl \n",
    "\n",
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"tokens\")\n",
    "\n",
    "normalizer = Normalizer()\\\n",
    "    .setInputCols([\"tokens\"])\\\n",
    "    .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "    .setInputCols(\"normalized\")\\\n",
    "    .setOutputCol(\"cleanTokens\")\\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "lemma = LemmatizerModel.pretrained(\"lemma_antbnc\")\\\n",
    "    .setInputCols([\"cleanTokens\"])\\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel().pretrained()\\\n",
    "    .setInputCols([\"document\", \"lemma\"])\\\n",
    "    .setOutputCol(\"embeddings\")\\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "clf_dl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"fraudulent\")\\\n",
    "    .setMaxEpochs(7)\\\n",
    "    .setEnableOutputLogs(True)\n",
    "\n",
    "clf_pipeline = Pipeline(stages=\n",
    "        [document_assembler, \n",
    "         tokenizer, \n",
    "         normalizer, \n",
    "         stopwords_cleaner,\n",
    "         lemma,\n",
    "         word_embeddings,\n",
    "         embeddingsSentence,\n",
    "         clf_dl])\n",
    "\n",
    "\n",
    "\n",
    "splits = df.randomSplit([0.8, 0.2])     # έχει αλλάξει το δf αυτό δεν είναι το προηγούμενο\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "clf_pipelineModel = clf_pipeline.fit(train)\n",
    "\n",
    "preds = clf_pipelineModel.transform(test)\n",
    "preds_df = preds.select('fraudulent','description',\"class.result\").toPandas()\n",
    "preds_df[\"result\"] = preds_df[\"result\"].apply(lambda x: x[0])\n",
    "print(classification_report(preds_df.fraudulent, preds_df.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfDqvc4O6eQj",
    "outputId": "ad588a9d-992c-4881-e73d-e24448f6c91e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|fraudulent|count|\n",
      "+----------+-----+\n",
      "|         0|17014|\n",
      "|         1|  866|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# επειδή και εδώ αναμέναμε κακά αποτελέσματα, κάναμε πρώτα oversampling στο αρχικό df και μετά κάναμε word embeddings\n",
    "# ας δούμε τώρα τι επιστρλεφει το classification report στο dataset το αρχικό\n",
    "# Χωρίς oversampling word embeddings\n",
    "\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"quote\", \"\\\"\")\\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreTrailingWhiteSpace\", True) \\\n",
    "    .csv(\"job_postings.csv\")\n",
    "\n",
    "c = df.groupBy(\"fraudulent\").count()\n",
    "c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Frk8cAYo6w47",
    "outputId": "495a065e-d061-4cbe-f7e7-f8d128c71c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      3384\n",
      "           1       0.00      0.00      0.00       167\n",
      "\n",
      "    accuracy                           0.95      3551\n",
      "   macro avg       0.48      0.50      0.49      3551\n",
      "weighted avg       0.91      0.95      0.93      3551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#CLASSIFIERDL USING WORD EMBEDDINGS (PRETRAINED)\n",
    "\n",
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"tokens\")\n",
    "\n",
    "normalizer = Normalizer()\\\n",
    "    .setInputCols([\"tokens\"])\\\n",
    "    .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "    .setInputCols(\"normalized\")\\\n",
    "    .setOutputCol(\"cleanTokens\")\\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "lemma = LemmatizerModel.pretrained(\"lemma_antbnc\")\\\n",
    "    .setInputCols([\"cleanTokens\"])\\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel().pretrained()\\\n",
    "    .setInputCols([\"document\", \"lemma\"])\\\n",
    "    .setOutputCol(\"embeddings\")\\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "clf_dl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"fraudulent\")\\\n",
    "    .setMaxEpochs(7)\\\n",
    "    .setEnableOutputLogs(True)\n",
    "\n",
    "clf_pipeline = Pipeline(stages=\n",
    "        [document_assembler, \n",
    "         tokenizer, \n",
    "         normalizer, \n",
    "         stopwords_cleaner,\n",
    "         lemma,\n",
    "         word_embeddings,\n",
    "         embeddingsSentence,\n",
    "         clf_dl])\n",
    "\n",
    "\n",
    "\n",
    "splits = df.randomSplit([0.8, 0.2])     \n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "clf_pipelineModel = clf_pipeline.fit(train)\n",
    "\n",
    "preds = clf_pipelineModel.transform(test)\n",
    "preds_df = preds.select('fraudulent','description',\"class.result\").toPandas()\n",
    "preds_df[\"result\"] = preds_df[\"result\"].apply(lambda x: x[0])\n",
    "print(classification_report(preds_df.fraudulent, preds_df.result))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WORD_EMBEDDINGS WITH CLASSIFIERDL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
